{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from glob import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(data_dir,label_dir):\n",
    "    img_width=random.randint(170,241)\n",
    "    img_height=img_width\n",
    "    numpy_image = []\n",
    "    numpy_label = []\n",
    "    D = {}\n",
    "\n",
    "    with tf.name_scope('input'):\n",
    "        label_list=label_dir\n",
    "        image_list=data_dir\n",
    "\n",
    "        temp = np.array([image_list, label_list])\n",
    "        temp = temp.transpose()\n",
    "        np.random.shuffle(temp)\n",
    "    \n",
    "        image_list = list(temp[:, 0])\n",
    "        label_list = list(temp[:, 1])\n",
    "        label_list = [round(float(i)) for i in label_list] \n",
    "        \n",
    "        image = tf.cast(image_list, tf.string)\n",
    "        label = tf.cast(label_list, tf.int32)\n",
    "\n",
    "        # make an input queue\n",
    "        input_queue = tf.data.Dataset.from_tensor_slices((image,label))\n",
    "\n",
    "        for ele in list(iter(input_queue)):\n",
    "            next_item = ele\n",
    "            print(next_item)\n",
    "\n",
    "            label = next_item[1]\n",
    "            label = tf.cast(label, tf.int32)\n",
    "\n",
    "            image_contents = tf.io.read_file(next_item[0])\n",
    "            image = tf.image.decode_jpeg(image_contents, channels=3)              \n",
    "\n",
    "            image = tf.cast(image, tf.float32)\n",
    "\n",
    "            image = tf.image.resize_with_crop_or_pad(image, img_width,  img_height)\n",
    "            image = tf.image.resize(image, [80, 80],method=tf.image.ResizeMethod.BILINEAR) \n",
    "\n",
    "            image = tf.cast(image, tf.float32)\n",
    "            \n",
    "            numpy_image.append(image.numpy())\n",
    "            numpy_label.append(label.numpy())\n",
    "            \n",
    "        \n",
    "        for numpy_image,numpy_label in zip(numpy_image,numpy_label):\n",
    "            D[numpy_label] = numpy_image\n",
    "        np.save('Preprocess1.npy', D)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Class2_1.jpg'>, <tf.Tensor: shape=(), dtype=int32, numpy=2>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Class3_4.jpg'>, <tf.Tensor: shape=(), dtype=int32, numpy=3>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Class4_0.jpg'>, <tf.Tensor: shape=(), dtype=int32, numpy=4>)\n"
     ]
    }
   ],
   "source": [
    "images = glob(\"Class*_*.jpg\")\n",
    "label = [2,3,4]\n",
    "get_images(images,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('Preprocess1.npz', image, allow_pickle=True)\n",
    "b = np.load('Preprocess1.npy', allow_pickle=True)\n",
    "# data = dict(np.load('Preprocess1.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b[()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b.item().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in b.item().items():\n",
    "     h = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 0-dimensional, but 1 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-287-10a55023c887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 0-dimensional, but 1 were indexed"
     ]
    }
   ],
   "source": [
    "im = Image.fromarray(np.uint8(b[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 64, 3), dtype=float32, numpy=\n",
       "array([[[54.918495, 55.804726, 53.034836],\n",
       "        [62.1752  , 61.54783 , 57.735664],\n",
       "        [58.2184  , 55.320618, 53.36759 ],\n",
       "        ...,\n",
       "        [58.456562, 58.58599 , 57.801037],\n",
       "        [65.748825, 65.87825 , 65.0933  ],\n",
       "        [59.069927, 59.199356, 58.414402]],\n",
       "\n",
       "       [[59.96923 , 60.855465, 56.286495],\n",
       "        [55.953445, 55.326073, 52.96779 ],\n",
       "        [56.645203, 53.752743, 52.96779 ],\n",
       "        ...,\n",
       "        [54.187366, 54.316795, 53.53184 ],\n",
       "        [57.011185, 57.140617, 56.355663],\n",
       "        [58.73173 , 58.86116 , 58.076206]],\n",
       "\n",
       "       [[56.272125, 57.15836 , 53.274887],\n",
       "        [55.921394, 55.29402 , 52.96779 ],\n",
       "        [58.14888 , 55.251095, 52.96779 ],\n",
       "        ...,\n",
       "        [62.420437, 62.549866, 61.76491 ],\n",
       "        [57.151905, 57.281334, 56.496384],\n",
       "        [58.224438, 58.353867, 57.568913]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[62.194702, 60.15718 , 56.815067],\n",
       "        [58.446167, 57.913395, 54.156216],\n",
       "        [55.191902, 56.078136, 52.96779 ],\n",
       "        ...,\n",
       "        [58.564995, 59.45123 , 54.913597],\n",
       "        [54.355873, 55.242104, 52.96779 ],\n",
       "        [55.21378 , 56.100014, 52.96779 ]],\n",
       "\n",
       "       [[62.47826 , 62.304253, 58.265408],\n",
       "        [56.616367, 57.502598, 53.530308],\n",
       "        [53.959625, 54.84586 , 52.96779 ],\n",
       "        ...,\n",
       "        [54.730137, 55.61637 , 52.996525],\n",
       "        [54.319687, 55.20592 , 52.96779 ],\n",
       "        [54.91165 , 55.797886, 52.96779 ]],\n",
       "\n",
       "       [[56.156326, 57.04256 , 53.18808 ],\n",
       "        [62.525223, 64.16826 , 59.599293],\n",
       "        [53.62603 , 56.79213 , 52.96779 ],\n",
       "        ...,\n",
       "        [57.88032 , 58.766552, 54.197586],\n",
       "        [56.43839 , 57.32462 , 52.96779 ],\n",
       "        [54.90398 , 55.79021 , 52.96779 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_crop =[]\n",
    "# for i in range(2):\n",
    "# image = tf.cast(h, tf.float32)\n",
    "random_crop = tf.image.random_crop(image, [64, 64, 3])\n",
    "random_crop = tf.image.rot90(random_crop,k=random.randint(0,3))\n",
    "random_crop = tf.image.random_flip_left_right(random_crop)\n",
    "random_crop = tf.image.random_brightness(random_crop, max_delta=63)\n",
    "im = tf.image.random_contrast(random_crop,lower=0.2,upper=1.8) \n",
    "# im = tf.image.per_image_standardization(im) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F721D86CA90>"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(np.uint8(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [2] vs. [3] [Op:GreaterEqual]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-258-c6f443f6fcb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRANDOM_CROP_FACTOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mrandom_crop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_crop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_crop\u001b[0;34m(value, size, seed, name)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     check = control_flow_ops.Assert(\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m\"Need value.shape >= size, got \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         summarize=1000)\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mgreater_equal\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   3983\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3984\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3985\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3986\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3987\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [2] vs. [3] [Op:GreaterEqual]"
     ]
    }
   ],
   "source": [
    "RANDOM_CROP_FACTOR = 2  #for dev purposes\n",
    "# def read_galaxy11(image):\n",
    "random_crop = []\n",
    "image_rot = []\n",
    "random_flip = []\n",
    "final = []\n",
    "\n",
    "#data augmentation\n",
    "for j in range(len(image)):\n",
    "    for i in range(RANDOM_CROP_FACTOR):\n",
    "        random_crop.append(tf.image.random_crop(image[i], [64, 64, 3]))\n",
    "\n",
    "for i in range(len(random_crop)):\n",
    "    for j in range(4):\n",
    "        image_rot.append(tf.image.rot90(random_crop[i],k=random.randint(0,3)))\n",
    "\n",
    "for i in range(len(image_rot)):\n",
    "    for j in range(2):\n",
    "        random_flip.append(tf.image.random_flip_left_right(image_rot[i]))\n",
    "\n",
    "for i in range(len(random_flip)):    \n",
    "    im = tf.image.random_brightness(random_flip[i], max_delta=63)\n",
    "    im = tf.image.random_contrast(im,lower=0.2,upper=1.8) \n",
    "    im = tf.image.per_image_standardization(im) \n",
    "    final.append(im)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
