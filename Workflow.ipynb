{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading pip-21.0.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow\n",
      "  Downloading tensorflow-2.4.1-cp36-cp36m-manylinux2010_x86_64.whl (394.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 394.3 MB 46 kB/s  eta 0:00:012   |█                               | 11.7 MB 5.5 MB/s eta 0:01:10     |██                              | 25.2 MB 6.3 MB/s eta 0:00:59     |██▌                             | 31.0 MB 5.1 MB/s eta 0:01:12     |██▋                             | 31.7 MB 5.1 MB/s eta 0:01:12     |██▊                             | 34.1 MB 8.6 MB/s eta 0:00:42     |███                             | 36.5 MB 8.6 MB/s eta 0:00:42     |██████▍                         | 79.0 MB 3.4 MB/s eta 0:01:34     |███████▍                        | 91.2 MB 15.9 MB/s eta 0:00:20     |███████▊                        | 94.7 MB 15.9 MB/s eta 0:00:19     |███████████                     | 136.4 MB 3.5 MB/s eta 0:01:14     |████████████▊                   | 156.5 MB 10.9 MB/s eta 0:00:22     |█████████████                   | 159.7 MB 656 kB/s eta 0:05:58     |███████████████████▉            | 244.6 MB 16.5 MB/s eta 0:00:10\n",
      "\u001b[?25hCollecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.8 MB 26.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tf_slim\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "\u001b[K     |████████████████████████████████| 352 kB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 16.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow\n",
      "  Downloading Pillow-8.2.0-cp36-cp36m-manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.1.48-cp36-cp36m-manylinux2014_x86_64.whl (50.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 50.4 MB 14.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting optuna\n",
      "  Downloading optuna-2.7.0-py3-none-any.whl (293 kB)\n",
      "\u001b[K     |████████████████████████████████| 293 kB 13.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-image\n",
      "  Downloading scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting optkeras\n",
      "  Downloading optkeras-0.0.7-py3-none-any.whl (6.9 kB)\n",
      "Collecting h5py==2.10.0\n",
      "  Downloading h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 32.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.5.0,>=2.4.0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.15.8-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 38.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py~=0.10\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "\u001b[K     |████████████████████████████████| 129 kB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 2.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 6.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 7.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 32.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wheel~=0.35\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /usr/lib64/python3.6/site-packages (from keras) (3.13)\n",
      "Collecting scipy>=0.14\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 30.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas) (2020.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.1-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.2 MB 25.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting alembic\n",
      "  Downloading alembic-1.5.8-py2.py3-none-any.whl (159 kB)\n",
      "\u001b[K     |████████████████████████████████| 159 kB 14.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-4.8.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.7.0-py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sqlalchemy>=1.1.0\n",
      "  Downloading SQLAlchemy-1.4.6-cp36-cp36m-manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 39.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.6/site-packages (from optuna) (20.4)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 7.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting networkx>=2.0\n",
      "  Downloading networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
      "\u001b[K     |████████████████████████████████| 148 kB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib!=3.0.0,>=2.0.0\n",
      "  Downloading matplotlib-3.3.4-cp36-cp36m-manylinux1_x86_64.whl (11.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.5 MB 29.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imageio>=2.3.0\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 27.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting setuptools>=41.0.0\n",
      "  Downloading setuptools-54.2.0-py3-none-any.whl (785 kB)\n",
      "\u001b[K     |████████████████████████████████| 785 kB 7.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 22.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 9.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "\u001b[K     |████████████████████████████████| 298 kB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.28.0-py2.py3-none-any.whl (136 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 136 kB 11.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 37.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 6.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.3.0-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pyparsing>=2.1.0 in /usr/local/lib/python3.6/site-packages (from cliff->optuna) (2.4.7)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.5.1-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 5.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-2.1.0-py3-none-any.whl (22 kB)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Downloading cmd2-1.5.0-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 29.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/site-packages (from sqlalchemy>=1.1.0->optuna) (1.7.0)\n",
      "Collecting greenlet!=0.4.17; python_version >= \"3\"\n",
      "  Downloading greenlet-1.0.0-cp36-cp36m-manylinux2010_x86_64.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.6/site-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 27.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.10)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.7)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.1-py3-none-any.whl (12 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.9.2 in /usr/local/lib64/python3.6/site-packages (from Mako->alembic->optuna) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/site-packages (from PrettyTable>=0.7.2->cliff->optuna) (0.2.5)\n",
      "Collecting colorama>=0.3.7\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=16.3.0 in /usr/local/lib/python3.6/site-packages (from cmd2>=1.0.0->cliff->optuna) (20.1.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.1.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 8.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 31.6 MB/s eta 0:00:01\n",
      "\u001b[?25hUsing legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for termcolor, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for wrapt, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for pyperclip, since package 'wheel' is not installed.\n",
      "Installing collected packages: pip, tensorflow-estimator, six, numpy, h5py, typing-extensions, flatbuffers, protobuf, gast, grpcio, absl-py, keras-preprocessing, opt-einsum, google-pasta, termcolor, setuptools, tensorboard-plugin-wit, markdown, werkzeug, wheel, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, astunparse, wrapt, tensorflow, scipy, keras, tf-slim, pandas, pillow, joblib, threadpoolctl, scikit-learn, sklearn, opencv-python, Mako, python-editor, greenlet, sqlalchemy, alembic, colorlog, pbr, stevedore, PrettyTable, colorama, pyperclip, cmd2, cliff, cmaes, tqdm, optuna, networkx, tifffile, kiwisolver, cycler, matplotlib, imageio, PyWavelets, scikit-image, optkeras\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.2.2\n",
      "    Uninstalling pip-20.2.2:\n",
      "      Successfully uninstalled pip-20.2.2\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.14.0\n",
      "    Uninstalling six-1.14.0:\n",
      "      Successfully uninstalled six-1.14.0\n",
      "    Running setup.py install for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 39.2.0\n",
      "    Uninstalling setuptools-39.2.0:\n",
      "      Successfully uninstalled setuptools-39.2.0\n",
      "    Running setup.py install for wrapt ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for pyperclip ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed Mako-1.1.4 PrettyTable-2.1.0 PyWavelets-1.1.1 absl-py-0.12.0 alembic-1.5.8 astunparse-1.6.3 cachetools-4.2.1 cliff-3.7.0 cmaes-0.8.2 cmd2-1.5.0 colorama-0.4.4 colorlog-4.8.0 cycler-0.10.0 flatbuffers-1.12 gast-0.3.3 google-auth-1.28.0 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 greenlet-1.0.0 grpcio-1.32.0 h5py-2.10.0 imageio-2.9.0 joblib-1.0.1 keras-2.4.3 keras-preprocessing-1.1.2 kiwisolver-1.3.1 markdown-3.3.4 matplotlib-3.3.4 networkx-2.5.1 numpy-1.19.5 oauthlib-3.1.0 opencv-python-4.5.1.48 opt-einsum-3.3.0 optkeras-0.0.7 optuna-2.7.0 pandas-1.1.5 pbr-5.5.1 pillow-8.2.0 pip-21.0.1 protobuf-3.15.8 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyperclip-1.8.2 python-editor-1.0.4 requests-oauthlib-1.3.0 rsa-4.7.2 scikit-image-0.17.2 scikit-learn-0.24.1 scipy-1.5.4 setuptools-54.2.0 six-1.15.0 sklearn-0.0 sqlalchemy-1.4.6 stevedore-3.3.0 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 tf-slim-1.1.0 threadpoolctl-2.1.0 tifffile-2020.9.3 tqdm-4.60.0 typing-extensions-3.7.4.3 werkzeug-1.0.1 wheel-0.36.2 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "!sudo pip3 install --upgrade pip tensorflow keras numpy tf_slim pandas pillow sklearn opencv-python optuna scikit-image  optkeras h5py==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo pip3 install keras==2.1.5 tensorflow==1.13.1 \n",
    "# !pip install --upgrade tf_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Pegasus.api.workflow.Workflow at 0x7ff20468ecc0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import requests \n",
    "from glob import glob\n",
    "from zipfile import ZipFile\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "#Import Pegasus API\n",
    "from Pegasus.api import *\n",
    "props = Properties()\n",
    "props[\"pegasus.mode\"] = \"development\"\n",
    "props.write()\n",
    "\n",
    "#Replica Catalog\n",
    "rc = ReplicaCatalog()\n",
    "in_files=[]\n",
    "\n",
    "label_csv = './inputs/training_solutions_rev1.csv'\n",
    "\n",
    "for file in glob(\"./inputs/*.jpg\"):\n",
    "    f = file.replace(\"./inputs/\", '')\n",
    "    in_files.append(File(f))\n",
    "    rc.add_replica(\"local\", File(f), Path(\"./inputs/\").resolve() / f)\n",
    "    \n",
    "csv = label_csv.replace(\"./inputs/\",'')\n",
    "rc.add_replica(\"local\", File(csv), Path(\"./inputs/\").resolve() / csv)\n",
    "rc.write()\n",
    "#Transformation\n",
    "\n",
    "data_label = Transformation( \"Data_Labeling.py.py\",\n",
    "            site=\"local\",\n",
    "            pfn=\"./bin/Data_Labeling.py\",\n",
    "            is_stageable=True\n",
    "            )\n",
    "training_preprocess1 = Transformation( \"Training_Preprocess1.py\",\n",
    "            site=\"local\",\n",
    "            pfn=\"./bin/Training_Preprocess1.py\",\n",
    "            is_stageable=True\n",
    "            )\n",
    "training_preprocess2 = Transformation( \"Training_Preprocess2.py\",\n",
    "            site=\"local\",\n",
    "            pfn=\"./bin/Training_Preprocess2.py\",\n",
    "            is_stageable=True\n",
    "            )\n",
    "val_preprocess = Transformation( \"Val_Preprocess.py\",\n",
    "            site=\"local\",\n",
    "            pfn=\"./bin/Val_Preprocess.py\",\n",
    "            is_stageable=True\n",
    "            )\n",
    "test_preprocess = Transformation( \"Test_Preprocess.py\",\n",
    "            site=\"local\",\n",
    "            pfn=\"./bin/Test_Preprocess.py\",\n",
    "            is_stageable=True\n",
    "            )\n",
    "tc = TransformationCatalog()\\\n",
    "    .add_transformations(data_label,training_preprocess1,training_preprocess2,val_preprocess, test_preprocess)\\\n",
    "    .write()\n",
    "\n",
    "#Workflow\n",
    "wf = Workflow(\"Galaxy\", infer_dependencies=True)\n",
    "\n",
    "dataset_without_file = []\n",
    "y = []\n",
    "for i in range(5):\n",
    "    dataset_without_file.append('Class0_'+ str(i)+'.jpg')\n",
    "    y.append(0)\n",
    "    dataset_without_file.append('Class1_'+ str(i)+'.jpg')\n",
    "    y.append(1)\n",
    "    dataset_without_file.append('Class2_'+ str(i)+'.jpg')\n",
    "    y.append(2)\n",
    "    dataset_without_file.append('Class3_'+ str(i)+'.jpg')\n",
    "    y.append(3)\n",
    "    dataset_without_file.append('Class4_'+ str(i)+'.jpg')\n",
    "    y.append(4)\n",
    "\n",
    "dataset = []\n",
    "for i in range(len(dataset_without_file)):\n",
    "    dataset.append(File(dataset_without_file[i]))\n",
    "\n",
    "job_data_label = Job(data_label)\\\n",
    "                    .add_inputs(*in_files, File(csv))\\\n",
    "                    .add_outputs(*dataset)\n",
    "        \n",
    "X = dataset_without_file\n",
    "\n",
    "X_train1, X_test, y_train1, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train1, y_train1, test_size=0.3, random_state=42, stratify = y_train1)\n",
    "\n",
    "train_images = []\n",
    "for i in range(len(X_train)):\n",
    "    train_images.append(File(X_train[i]))\n",
    "train_image_file1 = File(\"Training_images_Preprocess1.npy\")\n",
    "train_label_file1 = File(\"Training_labels_Preprocess1.npy\")\n",
    "job_training_preprocess1 = Job(training_preprocess1)\\\n",
    "                    .add_inputs(*train_images)\\\n",
    "                    .add_outputs(train_image_file1,train_label_file1)\n",
    "\n",
    "train_image_file2 = File(\"Training_images_Preprocess2.npy\")\n",
    "train_label_file2 = File(\"Training_labels_Preprocess2.npy\")\n",
    "job_training_preprocess2 = Job(training_preprocess2)\\\n",
    "                    .add_inputs(train_image_file1,train_label_file1)\\\n",
    "                    .add_outputs(train_image_file2,train_label_file2)\n",
    "val_images = []\n",
    "for i in range(len(X_val)):\n",
    "    val_images.append(File(X_val[i]))\n",
    "val_image_file = File(\"Val_images_Preprocess.npy\")\n",
    "val_label_file = File(\"Val_labels_Preprocess.npy\")\n",
    "job_val_preprocess = Job(val_preprocess)\\\n",
    "                    .add_inputs(*val_images)\\\n",
    "                    .add_outputs(val_image_file,val_label_file)\n",
    "\n",
    "test_images = []\n",
    "for i in range(len(X_test)):\n",
    "    test_images.append(File(X_test[i]))\n",
    "test_image_file = File(\"Test_images_Preprocess.npy\")\n",
    "test_label_file = File(\"Test_labels_Preprocess.npy\")\n",
    "job_test_preprocess = Job(test_preprocess)\\\n",
    "                    .add_inputs(*test_images)\\\n",
    "                    .add_outputs(test_image_file,test_label_file)\n",
    "\n",
    "wf.add_jobs(job_data_label,job_training_preprocess1,job_training_preprocess2,job_val_preprocess,job_test_preprocess)                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "################\n",
      "# pegasus-plan #\n",
      "################\n",
      "[main] WARN  schema.JsonMetaSchema  - Unknown keyword $defs - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword\n",
      "[main] WARN  schema.JsonMetaSchema  - Unknown keyword additionalItems - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword\n",
      "[main] WARN  schema.JsonMetaSchema  - Unknown keyword examples - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword\n",
      "2021.04.08 19:14:53.186 UTC:\n",
      "2021.04.08 19:14:53.192 UTC:   -----------------------------------------------------------------------\n",
      "2021.04.08 19:14:53.197 UTC:   File for submitting this DAG to HTCondor           : Galaxy-0.dag.condor.sub\n",
      "2021.04.08 19:14:53.202 UTC:   Log of DAGMan debugging messages                 : Galaxy-0.dag.dagman.out\n",
      "2021.04.08 19:14:53.208 UTC:   Log of HTCondor library output                     : Galaxy-0.dag.lib.out\n",
      "2021.04.08 19:14:53.213 UTC:   Log of HTCondor library error messages             : Galaxy-0.dag.lib.err\n",
      "2021.04.08 19:14:53.219 UTC:   Log of the life of condor_dagman itself          : Galaxy-0.dag.dagman.log\n",
      "2021.04.08 19:14:53.225 UTC:\n",
      "2021.04.08 19:14:53.230 UTC:   -no_submit given, not submitting DAG to HTCondor.  You can do this with:\n",
      "2021.04.08 19:14:53.241 UTC:   -----------------------------------------------------------------------\n",
      "2021.04.08 19:14:54.248 UTC:   Your database is compatible with Pegasus version: 5.0.0dev\n",
      "2021.04.08 19:14:55.720 UTC:   Created Pegasus database in: sqlite:////home/scitech/shared-data/Galaxy2/galaxy-image-classification/scitech/pegasus/Galaxy/run0001/Galaxy-0.replicas.db\n",
      "2021.04.08 19:14:55.726 UTC:   Your database is compatible with Pegasus version: 5.0.0dev\n",
      "2021.04.08 19:14:55.782 UTC:   Output replica catalog set to jdbc:sqlite:/home/scitech/shared-data/Galaxy2/galaxy-image-classification/scitech/pegasus/Galaxy/run0001/Galaxy-0.replicas.db\n",
      "2021.04.08 19:14:55.990 UTC:   Submitting to condor Galaxy-0.dag.condor.sub\n",
      "2021.04.08 19:14:56.026 UTC:\n",
      "2021.04.08 19:14:56.031 UTC:   Your workflow has been started and is running in the base directory:\n",
      "2021.04.08 19:14:56.037 UTC:\n",
      "2021.04.08 19:14:56.043 UTC:   /home/scitech/shared-data/Galaxy2/galaxy-image-classification/scitech/pegasus/Galaxy/run0001\n",
      "2021.04.08 19:14:56.049 UTC:\n",
      "2021.04.08 19:14:56.055 UTC:   *** To monitor the workflow you can run ***\n",
      "2021.04.08 19:14:56.061 UTC:\n",
      "2021.04.08 19:14:56.067 UTC:   pegasus-status -l /home/scitech/shared-data/Galaxy2/galaxy-image-classification/scitech/pegasus/Galaxy/run0001\n",
      "2021.04.08 19:14:56.073 UTC:\n",
      "2021.04.08 19:14:56.079 UTC:   *** To remove your workflow run ***\n",
      "2021.04.08 19:14:56.086 UTC:\n",
      "2021.04.08 19:14:56.092 UTC:   pegasus-remove /home/scitech/shared-data/Galaxy2/galaxy-image-classification/scitech/pegasus/Galaxy/run0001\n",
      "2021.04.08 19:14:56.681 UTC:   Time taken to execute is 5.155 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1;32m##\u001b[0m------------------------------------------------]   5.0% ..Running (\u001b[1;32mCompleted: 1\u001b[0m, \u001b[1;33mQueued: 0\u001b[0m, \u001b[1;36mRunning: 3\u001b[0m, \u001b[1;31mFailed: 0\u001b[0m)"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-466fc3ff2ba8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m      \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pegasus/dist/pegasus-5.0.0dev/lib64/python3.6/site-packages/Pegasus/api/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pegasus/dist/pegasus-5.0.0dev/lib64/python3.6/site-packages/Pegasus/api/workflow.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pegasus/dist/pegasus-5.0.0dev/lib64/python3.6/site-packages/Pegasus/api/workflow.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pegasus/dist/pegasus-5.0.0dev/lib64/python3.6/site-packages/Pegasus/api/workflow.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, delay)\u001b[0m\n\u001b[1;32m    894\u001b[0m         \"\"\"\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_chained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pegasus/dist/pegasus-5.0.0dev/lib64/python3.6/site-packages/Pegasus/client/_client.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, root_wf_name, submit_dir, delay)\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmit_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "     wf.plan(submit=True)\\\n",
    "        .wait()\\\n",
    "        .analyze()\\\n",
    "        .statistics()\n",
    "except PegasusClientError as e:\n",
    "    print(e.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
